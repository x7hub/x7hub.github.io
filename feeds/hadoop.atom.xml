<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>x7's blog</title><link href="http://x7hub.github.io/" rel="alternate"></link><link href="http://x7hub.github.io/feeds/hadoop.atom.xml" rel="self"></link><id>http://x7hub.github.io/</id><updated>2013-06-21T00:00:00+08:00</updated><entry><title>hadoop on archlinux</title><link href="http://x7hub.github.io/pages/hadoop_on_archlinux.html" rel="alternate"></link><updated>2013-06-21T00:00:00+08:00</updated><author><name>x7</name></author><id>tag:x7hub.github.io,2013-06-21:pages/hadoop_on_archlinux.html</id><summary type="html">&lt;p&gt;搬迁自&lt;a href="http://blog.sina.com.cn/s/blog_76db5e270101nu7o.html"&gt;以前的新浪博客&lt;/a&gt;～&lt;/p&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;p&gt;&lt;a href="https://wiki.archlinux.org/index.php/Hadoop"&gt;Hadoop - ArchWiki&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://hadoop.apache.org/docs/stable/single_node_setup.html"&gt;Single Node Setup&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;安装：&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;yaourt hadoop
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;主要目录是这个：&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;/etc/hadoop/
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;当然配置文件还是在这里。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;/etc/hadoop/
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;检查java环境配置。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$JAVA_HOME&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;安装时生成了rsa密钥一对，还需要将本地用户的公钥添加到&lt;code&gt;/etc/hadoop/.ssh/authorized_keys&lt;/code&gt;,用于&lt;code&gt;ssh&lt;/code&gt;验证。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;格式化新的分布式文件系统&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;hadoop namenode -format
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;启动服务,需要防火墙打开&lt;code&gt;9000&lt;/code&gt;和&lt;code&gt;9001&lt;/code&gt;端口，即使单机hadoop也需要，不明&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;bin/start-all.sh
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;或者启动&lt;code&gt;systemd&lt;/code&gt;的一排service&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;启动后运行example测试，首先把测试用的文件写到&lt;code&gt;hadoop fs&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;hadoop fs -put /etc/hadoop input
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;运行测试&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;hadoop jar /usr/lib/hadoop/hadoop-examples-*.jar grep input output &lt;span class="s1"&gt;&amp;#39;dfs[a-z.]+&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;查看结果&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;hadoop fs -get output output
cat output/*
&lt;/pre&gt;&lt;/div&gt;</summary><category term="linux"></category><category term="hadoop"></category></entry></feed>